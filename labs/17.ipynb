{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 17: Density Estimation and Clustering\n",
    "\n",
    "*For the class on Wednesday, April 3rd*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Kernel Density Estimation (KDE) and Gaussian Mixture Model (GMM)\n",
    "\n",
    "We will use both the Kernel Density Estimation (KDE) and the Gaussian Mixture Model (GMM)\n",
    "to estimate the density distribution of a mock data set with two features. \n",
    "\n",
    "The code also serves as an example of how to make a contour plot in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = pd.read_csv(\"https://yymao.github.io/phys7730/data/lab17.csv\")\n",
    "xlim = (-5, 5)\n",
    "ylim = (-3, 5)\n",
    "\n",
    "plt.scatter(d.x, d.y)\n",
    "plt.xlim(*xlim)\n",
    "plt.ylim(*ylim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the variable `x`` is a 2D array the stores the value of x coordinate in the 2D space!\n",
    "x, y = np.meshgrid(np.linspace(*xlim, num=501), np.linspace(*ylim, num=501))\n",
    "print(x.shape)\n",
    "cs = plt.contourf(x, y, x)\n",
    "plt.colorbar(cs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.2)\n",
    "kde.fit(d)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16,5))\n",
    "\n",
    "ax[0].scatter(d.x, d.y, label=\"data\")\n",
    "ax[0].scatter(*kde.sample(100).T, s=5, label=\"cloned\")\n",
    "ax[0].legend()\n",
    "\n",
    "cs = ax[1].contourf(x, y, np.exp(kde.score_samples(np.stack([x.ravel(), y.ravel()]).T).reshape(x.shape)), levels=20)\n",
    "plt.colorbar(cs, ax=ax)\n",
    "\n",
    "for ax_this in ax:\n",
    "    ax_this.set_xlim(*xlim)\n",
    "    ax_this.set_ylim(*ylim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(d)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(16,5))\n",
    "\n",
    "ax[0].scatter(d.x, d.y, label=\"data\")\n",
    "ax[0].scatter(*gmm.sample(100)[0].T, s=5, label=\"cloned\")  # note the slightly different return behavior of .sample()\n",
    "ax[0].legend()\n",
    "\n",
    "cs = ax[1].contourf(x, y, np.exp(gmm.score_samples(np.stack([x.ravel(), y.ravel()]).T).reshape(x.shape)), levels=20)\n",
    "plt.colorbar(cs, ax=ax)\n",
    "\n",
    "for ax_this in ax:\n",
    "    ax_this.set_xlim(*xlim)\n",
    "    ax_this.set_ylim(*ylim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A Questions 1-4**: \n",
    "\n",
    "1. What are the orange points in the plots above? \n",
    "2. Compare the estimated distributions from the KDE and GMM methods. How do they differ?\n",
    "3. After you answer (2), adjust the `bandwidth` parameter for KDE (was set to 0.2) and\n",
    "   the `n_components` parameter for GMM (was set to 2) until you think both methods are giving a good fit. \n",
    "4. After your adjustment in (3), compare again the estimated distributions from the KDE and GMM methods. How do they differ now?\n",
    "\n",
    "--- \n",
    "*Write your answer to Part A Q1-4 here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_range = list(range(1, 7))\n",
    "\n",
    "scores = []\n",
    "aic = []\n",
    "bic = []\n",
    "for n_components in n_range:\n",
    "    gmm = GaussianMixture(n_components=n_components)\n",
    "    gmm.fit(d)\n",
    "    scores.append(gmm.score(d))\n",
    "    aic.append(gmm.aic(d))\n",
    "    bic.append(gmm.bic(d))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(14,5))\n",
    "\n",
    "ax[0].plot(n_range, scores, marker=\".\", c=\"C2\")\n",
    "ax[0].set_xlabel(\"Number of components\")\n",
    "ax[0].set_ylabel(\"Score\")\n",
    "\n",
    "ax[1].plot(n_range, aic, label=\"AIC\", marker=\".\")\n",
    "ax[1].plot(n_range, bic, label=\"BIC\", marker=\".\", ls=\"--\")\n",
    "ax[1].set_xlabel(\"Number of components\")\n",
    "ax[1].set_ylabel(\"AIC/BIC\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A Question 5**: \n",
    "\n",
    "5. Based on the plots above, what would be the best number of components to use for GMM?  How did you get your answer here? Does your answer agree with what you found in Q3?\n",
    "\n",
    "--- \n",
    "*Write your answer to Part A Q5 here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Clustering (K-means and GMM)\n",
    "\n",
    "Here we compare the K-means and GMM clustering methods on the same data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "n_clusters = 3  # TODO: change this when you answer Q3 below\n",
    "\n",
    "clu = KMeans(n_clusters=n_clusters)\n",
    "clu.fit(d)\n",
    "cluster_labels = clu.predict(d)\n",
    "print(\"Kmeans Silhouette\", silhouette_score(d, cluster_labels))\n",
    "\n",
    "gmm = GaussianMixture(n_components=n_clusters)\n",
    "gmm.fit(d)\n",
    "gmm_labels = gmm.predict(d)\n",
    "print(\"GMM    Silhouette\", silhouette_score(d, gmm_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(14,5))\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    mask = (cluster_labels == i)\n",
    "    ax[0].scatter(d.x[mask], d.y[mask])\n",
    "    mask = (gmm_labels == i)\n",
    "    ax[1].scatter(d.x[mask], d.y[mask])\n",
    "\n",
    "ax[0].set_title(\"K-means\")\n",
    "ax[1].set_title(\"GMM\")\n",
    "for ax_this in ax:\n",
    "    ax_this.set_xlim(*xlim)\n",
    "    ax_this.set_ylim(*ylim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B Questions**:\n",
    "\n",
    "1. For this data set, would you say the K-means and GMM methods give you consistent clustering results?\n",
    "2. Rerun these two cells a few times. Does each run give you the same result, or are there any differences?\n",
    "3. In the first cell of Part B, change to `n_clusters = 4` and rerun the two cells a few times. \n",
    "   Do K-means and GMM methods give you consistent clustering result every time you run them?\n",
    "   Briefly (2-3 sentences) explain what you observe. \n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "**How to submit this notebook on Canvas?**\n",
    "\n",
    "1. Make sure all your answers, code, and desired results are properly displayed in the notebook.\n",
    "2. Save the notebook (press `Ctrl`+`s` or `Cmd`+`s`). The grey dot on the filename tab (indicating \"unsaved\") should disappear. \n",
    "3. Run the following cell.\n",
    "4. Upload the resulting HTML file to Canvas under the corresponding assignment. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "! jupyter nbconvert --to html ./17.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
