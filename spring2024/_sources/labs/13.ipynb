{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 13: Regression II: Gaussian Process and Cross Validation\n",
    "\n",
    "*For the class on Monday, March 18th*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Gaussian Process Regression\n",
    "\n",
    "In this example, we have a simple data set with only one feature and one target. \n",
    "A simple linear regression does not fit this data set.\n",
    "We will test if Gaussian Process regression works well in this case.\n",
    "\n",
    "### A1. Compare Gaussian Process and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://yymao.github.io/phys7730/spring2024/data/lab13a.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_target, test_target = train_test_split(df[[\"feature1\"]], df[\"target\"], test_size=0.25, random_state=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that, despite the difference between `reg_lr` and `reg_gp`,\n",
    "# The code to fit the data and make prediction is almost identical.\n",
    "\n",
    "reg_lr = LinearRegression()\n",
    "reg_lr.fit(train_features, train_target)\n",
    "train_predict_lr = reg_lr.predict(train_features)\n",
    "test_predict_lr = reg_lr.predict(test_features)\n",
    "\n",
    "reg_gp = GaussianProcessRegressor(normalize_y=True)\n",
    "reg_gp.fit(train_features, train_target)\n",
    "train_predict_gp = reg_gp.predict(train_features)\n",
    "test_predict_gp = reg_gp.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "ax[0].scatter(train_predict_lr, train_target, c=\"C0\", s=20, label=\"Training\")\n",
    "ax[0].scatter(test_predict_lr, test_target, c=\"C2\", s=25, marker=\"^\", label=\"Test\")\n",
    "ax[0].set_title(\"Linear regression\")\n",
    "\n",
    "ax[1].scatter(train_predict_gp, train_target, c=\"C0\", s=20, label=\"Training\")\n",
    "ax[1].scatter(test_predict_gp, test_target, c=\"C2\", s=25, marker=\"^\", label=\"Test\")\n",
    "ax[1].set_title(\"Gaussian Process\")\n",
    "\n",
    "corners = [-7, 3]\n",
    "for ax_this in ax:\n",
    "    ax_this.plot(corners, corners, c=\"C1\", ls=\"--\", label=\"$y=x$\")\n",
    "    ax_this.set_xlim(*corners)\n",
    "    ax_this.set_ylim(*corners)\n",
    "\n",
    "    ax_this.set_xlabel(\"Predicted values\")\n",
    "    ax_this.set_ylabel(\"True target value\")\n",
    "    ax_this.legend(loc=\"lower right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A1, Question 1**: Based on the plots above, how would you compare the performace of the linear regression and the Gaussian Process regression?  \n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 7, 201)\n",
    "prediction_lr = reg_lr.predict(pd.DataFrame({\"feature1\": x}))\n",
    "mean_prediction_gp, std_prediction_gp = reg_gp.predict(pd.DataFrame({\"feature1\": x}), return_std=True)\n",
    "\n",
    "plt.scatter(train_features[\"feature1\"], train_target, label=\"Observations\")\n",
    "plt.plot(x, prediction_lr, label=\"Linear model prediction\", ls=\":\", c=\"C4\")\n",
    "plt.plot(x, mean_prediction_gp, label=\"GP mean prediction\", c=\"C3\")\n",
    "plt.fill_between(\n",
    "    x.ravel(),\n",
    "    mean_prediction_gp - 1.96 * std_prediction_gp,\n",
    "    mean_prediction_gp + 1.96 * std_prediction_gp,\n",
    "    alpha=0.25,\n",
    "    color=\"C3\",\n",
    "    label=r\"GP 95% confidence interval\",\n",
    "    lw=0,\n",
    ")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.ylim(-7, 6)\n",
    "plt.xlabel(\"feature1\")\n",
    "plt.ylabel(\"target\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A1, Questions 2-5**: \n",
    "\n",
    "2. Based on the plot above, does your evaluation of the linear regression and the Gaussian Process regression change?\n",
    "3. Why don't we see the GP 95% confidence interval on this plot?\n",
    "4. Which method do you think would give a better prediction when the `feature1` value is around 1?\n",
    "5. Which method do you think would give a better prediction when the `feature1` value is around 7?\n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Including data uncertainty\n",
    "\n",
    "1. Repeat A1 (including making those plots),\n",
    "   but change `GaussianProcessRegressor(normalize_y=True)` to `GaussianProcessRegressor(normalize_y=True, alpha=0.1)`. \n",
    "\n",
    "   :::{tip}\n",
    "   What is `alpha`? Roughly speaking it's the assumed uncertainty of data points (in target). \n",
    "   See the documentation of [`GaussianProcessRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html)\n",
    "   for detail.\n",
    "   :::\n",
    "\n",
    "2. Manually try a few different values of `alpha` (no need to refactor or optimize your code, as you'll see a better way in Part B). \n",
    "   What value seems to give you the best result?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your implementation to A2 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A2, Question 1**: During Step 2, what value of alpha seems to work well? How did you define \"work well\"?\n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Cross Validation\n",
    "\n",
    "In Part B, we will use cross validation to find the optimal values for the hyperparameter in our ML models. \n",
    "\n",
    "### B1. Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(GaussianProcessRegressor(normalize_y=True), train_features, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B1, Question 1**: What are these five values? Why are there 5 values but not other number of values?\n",
    "Check out the documentation of [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) if you are not sure. \n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cv = GridSearchCV(GaussianProcessRegressor(normalize_y=True), {\"alpha\": np.logspace(-8, 1, 31)})\n",
    "reg_cv.fit(train_features, train_target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(reg_cv.cv_results_[\"param_alpha\"].data, reg_cv.cv_results_[\"mean_test_score\"])\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"mean test score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B1, Question 2**: Based on the plot above, what value of `alpha` give the Gaussian Process model the best performance on this data set? \n",
    "Is this value similar to what you found in Part A2? \n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code to repeat A2, but with the `alpha` value you found here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Revisit Lab 12 Part B\n",
    "\n",
    "In [Lab 12](./12) Part B, we compare the logistic regression method with and without regularization. \n",
    "When regularization is included (the default option for `LogisticRegression`), we can in fact further adjust the regularization strength\n",
    "by changing the value supplied to the argument `C`. \n",
    "See the documentation of [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "for details.\n",
    "\n",
    "In this part, we will use the cross validation method to justify our discussion in Lab 12 Part B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12b = pd.read_csv(\"https://yymao.github.io/phys7730/spring2024/data/lab12b.csv\")\n",
    "train_12b_features, test_12b_features, train_12b_target, test_12b_target = train_test_split(df_12b.iloc[:,:3], df_12b[\"target\"], test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cv = GridSearchCV(LogisticRegression(), {\"C\": np.logspace(-3, 3, 31)})\n",
    "reg_cv.fit(train_12b_features, train_12b_target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(reg_cv.cv_results_[\"param_C\"].data, reg_cv.cv_results_[\"mean_test_score\"])\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"mean test score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B2, Question 1**: Based on the plot above, do you think including regularization is helpful for this particular data set? \n",
    "Note that the conclusion here is not a general statement! What do you think is special about this data set that results in your conclusion?\n",
    "\n",
    "\n",
    "--- \n",
    "*// Write your answer here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "**How to submit this notebook on Canvas?**\n",
    "\n",
    "1. Make sure all your answers, code, and desired results are properly displayed in the notebook.\n",
    "2. Save the notebook (press `Ctrl`+`s` or `Cmd`+`s`). The grey dot on the filename tab (indicating \"unsaved\") should disappear. \n",
    "3. Run the following cell.\n",
    "4. Upload the resulting HTML file to Canvas under the corresponding assignment. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "! jupyter nbconvert --to html ./13.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
