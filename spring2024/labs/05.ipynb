{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Importance Sampling\n",
    "\n",
    "*For the class on Monday, January 29th*\n",
    "\n",
    ":::{tip}\n",
    "Looking for [hints](../labs-extra/05)?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Aliens' Estimate of Human Population\n",
    "\n",
    "See the question about aliens' estimate of human population in the [Discussion Preview of Reading 05](reading-aliens-estimate). \n",
    "\n",
    "Based on the discussion you had with your partner in class, write down how you think the aliens should choose the 1,000 locations \n",
    "to get a more accurate estimate. \n",
    "\n",
    "(*Indicate your partner's name if applicable*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "*// Add your answers to A here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Double the Rewards!\n",
    "\n",
    "You are invited to a game where you flip a fair coin $n_\\text{flips} = 1,000$ times. \n",
    "Before the game starts, you are given 1 dollar as your base reward.\n",
    "Then, every time you get a \"heads\" in the game, the reward you have at that point doubles!\n",
    "\n",
    "\n",
    "### B1. Simple simulation\n",
    "\n",
    "If you plainly simulate this game $n_\\text{games} =100$ times, and calculate the average reward from the $n_\\text{games}$ games,\n",
    "**would you obtain an accurate estimate? Or, would you under- or over-estimate the expected reward?**\n",
    "\n",
    "**Briefly explain your answer, and then verify your answer with the code below.**\n",
    "\n",
    ":::{tip}\n",
    "Because the reward from each game can be a very large number, to reduce numerical errors, we will store the logarithm instead. \n",
    "Let $r_i = 2^{n_\\text{heads}}$ denote the reward from the $i$th-game, and $y_i = \\log r_i$ the logarithm of the reward, which we will store.\n",
    "Then, the logarithm of the average of rewards from multiple games can be written as:\n",
    "\n",
    "$$ \n",
    "  \\log \\left[ \\frac{1}{n_\\text{games}} \\sum_i \\exp(y_i) \\right]\n",
    "$$\n",
    "\n",
    "This can be done directly by `scipy.special.logsumexp(y, b=1/n_games)`. \n",
    "See [`scipy.special.logsumexp`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.logsumexp.html) for detail.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "*// Add your answers to B1 here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common code needed for both B1 and B2\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def run_one_game(n_flips, p_heads):\n",
    "    \"\"\"\n",
    "    Generates the result of a coin flip game with `n_flips`.\n",
    "    Heads are represented by 1 in the returned array, tails by 0.\n",
    "    The coin has a probability `p_heads` for showing heads.\n",
    "    \"\"\"\n",
    "    return np.random.default_rng().choice([0,1], size=n_flips, p=[1.0-p_heads, p_heads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for B1 (You only need to edit the last line)\n",
    "\n",
    "n_flips = 1000\n",
    "n_games = 100\n",
    "n_sims = 500\n",
    "\n",
    "log_average_reward_each_sim = []\n",
    "for _ in range(n_sims):\n",
    "\n",
    "    log_reward_each_game = []\n",
    "    for _ in range(n_games):\n",
    "        game_result = run_one_game(n_flips, 1/2)\n",
    "        n_heads = np.count_nonzero(game_result)\n",
    "        log_reward = np.log(2) * n_heads\n",
    "        log_reward_each_game.append(log_reward)\n",
    "\n",
    "    log_average_reward = logsumexp(log_reward_each_game, b=1/n_games)\n",
    "    log_average_reward_each_sim.append(log_average_reward)\n",
    "\n",
    "plt.hist(log_average_reward_each_sim, 20, alpha=0.3);\n",
    "plt.axvline(np.median(log_average_reward_each_sim), c=\"C0\", ls=\"--\");\n",
    "plt.xlabel(\"log average reward per game\");\n",
    "\n",
    "## TODO: Uncomment the line below and replace ... with the theoretical expected value. Verify your answer in B1.\n",
    "#plt.axvline(..., c=\"C3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  B2. Importance sampling with a biased coin\n",
    "\n",
    "We can get a better estimate by implementing importance sampling using a *biased* coin.\n",
    "\n",
    "Consider a specific result from one game (i.e., a specific configuration of $n_\\text{flips}$ heads and tails),\n",
    "the likelihood of getting this particular configuration with a fair coin would differ from that with a biased coin.\n",
    "If the biased coin has a probability $p_\\text{biased}$ for getting heads, the likelihood ratio would be\n",
    "\n",
    "$$\n",
    "  w = \\frac{(\\frac{1}{2})^{n_\\text{heads}} \\cdot (\\frac{1}{2})^{(n_\\text{flips} - n_\\text{heads})} }{p_\\text{biased}^{n_\\text{heads}} \\cdot (1-p_\\text{biased})^{(n_\\text{flips} - n_\\text{heads})} }\n",
    "$$\n",
    "\n",
    "In this case, the logarithm of the average of rewards should be written as \n",
    "\n",
    "$$ \n",
    "  \\log \\left\\{ \\frac{1}{n_\\text{games}} \\sum_i \\left[ \\exp(y'_i) \\cdot w_i \\right] \\right\\}\n",
    "$$\n",
    "\n",
    "where $y'_i$ are the logarithmic rewards sampled from games with a biased coin.\n",
    "\n",
    "\n",
    "Rerun the simulation with $p_\\text{biased} = 0.7$ (see code below). \n",
    "**Do you think the estimate will improve? Would you still under- or over-estimate the expected reward?**\n",
    "\n",
    "**Make a guess and then verify your answer with the code below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "*// Add your answers to B2 here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for B2 (You only need to edit the last line)\n",
    "\n",
    "def calc_log_likelihood_ratio(n_flips, n_heads, p_biased):\n",
    "    \"\"\"\n",
    "    Calculates the log of likelihood ratio (w)\n",
    "    \"\"\"\n",
    "    return np.log(0.5 / p_biased) * n_heads + np.log(0.5 / (1.0 - p_biased)) * (n_flips - n_heads)\n",
    "\n",
    "\n",
    "n_flips = 1000\n",
    "n_games = 100\n",
    "n_sims = 500\n",
    "p_biased = 0.7\n",
    "\n",
    "log_average_reward_each_sim = []\n",
    "for _ in range(n_sims):\n",
    "\n",
    "    log_reward_each_game = []\n",
    "    log_weight_each_game = []\n",
    "    for _ in range(n_games):\n",
    "        game_result = run_one_game(n_flips, p_biased)\n",
    "        n_heads = np.count_nonzero(game_result)\n",
    "        log_reward = np.log(2) * n_heads\n",
    "        log_reward_each_game.append(log_reward)\n",
    "        log_weight = calc_log_likelihood_ratio(n_flips, n_heads, p_biased)\n",
    "        log_weight_each_game.append(log_weight)\n",
    "\n",
    "    # Note that in the line below we add log reward and low weight from each game together for importance sample\n",
    "    # Compare this line with the formula above!\n",
    "    log_average_reward = logsumexp(np.add(log_reward_each_game, log_weight_each_game), b=1/n_games)\n",
    "    log_average_reward_each_sim.append(log_average_reward)\n",
    "\n",
    "plt.hist(log_average_reward_each_sim, 20, alpha=0.3);\n",
    "plt.axvline(np.median(log_average_reward_each_sim), c=\"C0\", ls=\"--\");\n",
    "plt.xlabel(f\"log average reward per game (p_biased = {p_biased})\");\n",
    "\n",
    "## TODO: Uncomment the line below and replace ... with the theoretical expected value. Verify your answer in B2.\n",
    "#plt.axvline(..., c=\"C3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  B3. Optimal choice of the proposed distribution\n",
    "\n",
    "1. Run B2 with different values of `p_biased` (for example, 0.01, 0.02, ..., 0.99).\n",
    "   For each value of `p_biased`, \n",
    "   use `np.median(log_average_reward_each_sim)` to represent the \"typical\" logarithmic average reward (averaged over $n_\\text{games}$ games)\n",
    "   for that value of `p_biased`. \n",
    "   Reduce `n_sims` to 10 to keep the runtime short. \n",
    "\n",
    "2. Plot the typical logarithmic average reward as a function of $p_\\text{biased}$.\n",
    "\n",
    "**What value of $p_\\text{biased}$ would give you an estimate that is the closest to the theoretical expected value?**\n",
    "**Can you explain why this value works the best?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "*// Add your answers to B3 here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for B3 (check hint if you don't know where to start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final question\n",
    "\n",
    "Roughly how much time did you spend on this lab (*not* including the time you spent in class)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "*// Write your answers here*\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "**How to submit this notebook on Canvas?**\n",
    "\n",
    "Once you complete this lab and have all your code, text answers, and all the desired results after running the notebook properly displayed in this notebook, \n",
    "please convert the notebook into HTML format by running the following:\n",
    "\n",
    "```sh\n",
    "jupyter nbconvert --to html /path/to/labs/05.ipynb \n",
    "```\n",
    "\n",
    "Then, upload the resulting HTML file to Canvas for the corresponding assignment. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
